{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "instanceseg-nyoki-mtl-gpu_fullsize_211122.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "DIZf8qAAWDAJ"
      },
      "source": [
        "import sys\n",
        "import numpy as np\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "!pip install e2cnn==0.1.7\n",
        "import e2cnn.nn as nn\n",
        "\n",
        "np.random.seed(17)\n",
        "%matplotlib inline\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nY17cpZAAPXy"
      },
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "#verify GPU available\n",
        "torch.cuda.is_available()\n",
        "torch.cuda.current_device()\n",
        "torch.cuda.device(0)\n",
        "torch.cuda.device_count()\n",
        "torch.cuda.get_device_name(0)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print('Using device:', device)\n",
        "print()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aIgkATrrWFsX"
      },
      "source": [
        "\n",
        "class SSSDataset(Dataset):\n",
        "    def __init__(self, train, n_sticks=8, data_size=512):#data_size = 512 originally\n",
        "        super().__init__()\n",
        "        self.train = train\n",
        "        self.n_sticks = n_sticks\n",
        "        self.data_size = data_size\n",
        "        self.height = 256\n",
        "        self.width = 256\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.data_size\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        while True:\n",
        "            img = np.ones((self.height, self.width), dtype=np.uint8) * 255\n",
        "            ins = np.zeros((0, self.height, self.width), dtype=np.uint8)\n",
        "            for _ in range(self.n_sticks):\n",
        "                x = np.random.randint(30, 225)\n",
        "                y = np.random.randint(30, 225)\n",
        "                w = 15\n",
        "                h = np.random.randint(80, 100)\n",
        "                theta = np.random.randint(-90, 90)\n",
        "                rect = ([x, y], [w, h], theta)\n",
        "                box = np.int0(cv2.boxPoints(rect))\n",
        "\n",
        "                gt = np.zeros_like(img)\n",
        "                gt = cv2.fillPoly(gt, [box], 1)\n",
        "                ins[:, gt != 0] = 0\n",
        "                ins = np.concatenate([ins, gt[np.newaxis]])\n",
        "                img = cv2.fillPoly(img, [box], 255)\n",
        "                img = cv2.drawContours(img, [box], 0, 0, 2)\n",
        "\n",
        "            # minimum area of stick\n",
        "            if np.sum(np.sum(ins, axis=(1, 2)) < 400) == 0:\n",
        "                break\n",
        "\n",
        "        if self.train:\n",
        "            sem = np.zeros_like(img, dtype=bool)\n",
        "            sem[np.sum(ins, axis=0) != 0] = True\n",
        "            sem = np.stack([~sem, sem]).astype(np.uint8)\n",
        "\n",
        "            # 1 * height * width\n",
        "            img = torch.Tensor(img[np.newaxis])\n",
        "            # 2 * height * width\n",
        "            sem = torch.Tensor(sem)\n",
        "            # n_sticks * height * width\n",
        "            ins = torch.Tensor(ins)\n",
        "            return img, sem, ins\n",
        "        else:\n",
        "            # 1 * height * width\n",
        "            img = torch.Tensor(img[np.newaxis])\n",
        "            return img, ins\n",
        "          \n",
        "\n",
        "\"\"\"\n",
        "This is the implementation of following paper:\n",
        "https://arxiv.org/pdf/1802.05591.pdf\n",
        "This implementation is based on following code:\n",
        "https://github.com/Wizaron/instance-segmentation-pytorch\n",
        "\"\"\"\n",
        "from torch.nn.modules.loss import _Loss\n",
        "from torch.autograd import Variable\n",
        "import torch\n",
        "\n",
        "\n",
        "class DiscriminativeLoss(_Loss):\n",
        "\n",
        "    def __init__(self, delta_var=0.5, delta_dist=1.5,\n",
        "                 norm=2, alpha=1.0, beta=1.0, gamma=0.001,\n",
        "                 usegpu=True, size_average=True):\n",
        "        super(DiscriminativeLoss, self).__init__(size_average)\n",
        "        self.delta_var = delta_var\n",
        "        self.delta_dist = delta_dist\n",
        "        self.norm = norm\n",
        "        self.alpha = alpha\n",
        "        self.beta = beta\n",
        "        self.gamma = gamma\n",
        "        self.usegpu = usegpu\n",
        "        assert self.norm in [1, 2]\n",
        "\n",
        "    def forward(self, input, target, n_clusters):\n",
        "        return self._discriminative_loss(input, target, n_clusters)\n",
        "\n",
        "    def _discriminative_loss(self, input, target, n_clusters):\n",
        "        bs, n_features, height, width = input.size()\n",
        "        max_n_clusters = target.size(1)\n",
        "\n",
        "        input = input.contiguous().view(bs, n_features, height * width)\n",
        "        target = target.contiguous().view(bs, max_n_clusters, height * width)\n",
        "\n",
        "        c_means = self._cluster_means(input, target, n_clusters)\n",
        "        l_var = self._variance_term(input, target, c_means, n_clusters)\n",
        "        l_dist = self._distance_term(c_means, n_clusters)\n",
        "        l_reg = self._regularization_term(c_means, n_clusters)\n",
        "\n",
        "        loss = self.alpha * l_var + self.beta * l_dist + self.gamma * l_reg\n",
        "\n",
        "        return loss\n",
        "\n",
        "    def _cluster_means(self, input, target, n_clusters):\n",
        "        bs, n_features, n_loc = input.size()\n",
        "        max_n_clusters = target.size(1)\n",
        "\n",
        "        # bs, n_features, max_n_clusters, n_loc\n",
        "        input = input.unsqueeze(2).expand(bs, n_features, max_n_clusters, n_loc)\n",
        "        # bs, 1, max_n_clusters, n_loc\n",
        "        target = target.unsqueeze(1)\n",
        "        # bs, n_features, max_n_clusters, n_loc\n",
        "        input = input * target\n",
        "\n",
        "        means = []\n",
        "        for i in range(bs):\n",
        "            # n_features, n_clusters, n_loc\n",
        "            input_sample = input[i, :, :n_clusters[i]]\n",
        "            # 1, n_clusters, n_loc,\n",
        "            target_sample = target[i, :, :n_clusters[i]]\n",
        "            # n_features, n_cluster\n",
        "            mean_sample = input_sample.sum(2) / target_sample.sum(2)\n",
        "\n",
        "            # padding\n",
        "            n_pad_clusters = max_n_clusters - n_clusters[i]\n",
        "            assert n_pad_clusters >= 0\n",
        "            if n_pad_clusters > 0:\n",
        "                pad_sample = torch.zeros(n_features, n_pad_clusters)\n",
        "                pad_sample = Variable(pad_sample)\n",
        "                if self.usegpu:\n",
        "                    pad_sample = pad_sample.cuda()\n",
        "                mean_sample = torch.cat((mean_sample, pad_sample), dim=1)\n",
        "            means.append(mean_sample)\n",
        "\n",
        "        # bs, n_features, max_n_clusters\n",
        "        means = torch.stack(means)\n",
        "\n",
        "        return means\n",
        "\n",
        "    def _variance_term(self, input, target, c_means, n_clusters):\n",
        "        bs, n_features, n_loc = input.size()\n",
        "        max_n_clusters = target.size(1)\n",
        "\n",
        "        # bs, n_features, max_n_clusters, n_loc\n",
        "        c_means = c_means.unsqueeze(3).expand(bs, n_features, max_n_clusters, n_loc)\n",
        "        # bs, n_features, max_n_clusters, n_loc\n",
        "        input = input.unsqueeze(2).expand(bs, n_features, max_n_clusters, n_loc)\n",
        "        # bs, max_n_clusters, n_loc\n",
        "        var = (torch.clamp(torch.norm((input - c_means), self.norm, 1) -\n",
        "                           self.delta_var, min=0) ** 2) * target\n",
        "\n",
        "        var_term = 0\n",
        "        for i in range(bs):\n",
        "            # n_clusters, n_loc\n",
        "            var_sample = var[i, :n_clusters[i]]\n",
        "            # n_clusters, n_loc\n",
        "            target_sample = target[i, :n_clusters[i]]\n",
        "\n",
        "            # n_clusters\n",
        "            c_var = var_sample.sum(1) / target_sample.sum(1)\n",
        "            var_term += c_var.sum() / n_clusters[i]\n",
        "        var_term /= bs\n",
        "\n",
        "        return var_term\n",
        "\n",
        "    def _distance_term(self, c_means, n_clusters):\n",
        "        bs, n_features, max_n_clusters = c_means.size()\n",
        "\n",
        "        dist_term = 0\n",
        "        for i in range(bs):\n",
        "            if n_clusters[i] <= 1:\n",
        "                continue\n",
        "\n",
        "            # n_features, n_clusters\n",
        "            mean_sample = c_means[i, :, :n_clusters[i]]\n",
        "\n",
        "            # n_features, n_clusters, n_clusters\n",
        "            means_a = mean_sample.unsqueeze(2).expand(n_features, n_clusters[i], n_clusters[i])\n",
        "            means_b = means_a.permute(0, 2, 1)\n",
        "            diff = means_a - means_b\n",
        "\n",
        "            margin = 2 * self.delta_dist * (1.0 - torch.eye(n_clusters[i]))\n",
        "            margin = Variable(margin)\n",
        "            if self.usegpu:\n",
        "                margin = margin.cuda()\n",
        "            c_dist = torch.sum(torch.clamp(margin - torch.norm(diff, self.norm, 0), min=0) ** 2)\n",
        "            dist_term += c_dist / (2 * n_clusters[i] * (n_clusters[i] - 1))\n",
        "        dist_term /= bs\n",
        "\n",
        "        return dist_term\n",
        "\n",
        "    def _regularization_term(self, c_means, n_clusters):\n",
        "        bs, n_features, max_n_clusters = c_means.size()\n",
        "\n",
        "        reg_term = 0\n",
        "        for i in range(bs):\n",
        "            # n_features, n_clusters\n",
        "            mean_sample = c_means[i, :, :n_clusters[i]]\n",
        "            reg_term += torch.mean(torch.norm(mean_sample, self.norm, 0))\n",
        "        reg_term /= bs\n",
        "\n",
        "        return reg_term\n",
        "\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "def gen_mask(ins_img):\n",
        "    mask = []\n",
        "    for i, mask_i in enumerate(ins_img):\n",
        "        binarized = mask_i * (i + 1)\n",
        "        mask.append(binarized)\n",
        "    mask = np.sum(np.stack(mask, axis=0), axis=0).astype(np.uint8)\n",
        "    return mask\n",
        "\n",
        "\n",
        "def coloring(mask):\n",
        "    ins_color_img = np.zeros((mask.shape[0], mask.shape[1], 3), dtype=np.uint8)\n",
        "    n_ins = len(np.unique(mask)) - 1\n",
        "    colors = [plt.cm.Spectral(each) for each in np.linspace(0, 1, n_ins)]\n",
        "    for i in range(n_ins):\n",
        "        ins_color_img[mask == i + 1] =\\\n",
        "            (np.array(colors[i][:3]) * 255).astype(np.uint8)\n",
        "    return ins_color_img\n",
        "\n",
        "\n",
        "def gen_instance_mask(sem_pred, ins_pred, n_obj):\n",
        "    embeddings = ins_pred[:, sem_pred].transpose(1, 0)\n",
        "    clustering = KMeans(n_obj).fit(embeddings)\n",
        "    labels = clustering.labels_\n",
        "\n",
        "    instance_mask = np.zeros_like(sem_pred, dtype=np.uint8)\n",
        "    for i in range(n_obj):\n",
        "        lbl = np.zeros_like(labels, dtype=np.uint8)\n",
        "        lbl[labels == i] = i + 1\n",
        "        instance_mask[sem_pred] += lbl\n",
        "\n",
        "    return instance_mask\n",
        "\n",
        "\n",
        "def gen_color_img(sem_pred, ins_pred, n_obj):\n",
        "    return coloring(gen_instance_mask(sem_pred, ins_pred, n_obj))\n",
        "\n",
        "\n",
        "print('import done')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2V4sa5yrWLU5"
      },
      "source": [
        "n_sticks = 8\n",
        "height = 256\n",
        "width = 256\n",
        "\n",
        "while True:\n",
        "    img = np.ones((height, width), dtype=np.uint8) * 255\n",
        "    ins = np.zeros((0, height, width), dtype=np.uint8)\n",
        "    for _ in range(n_sticks):\n",
        "        x = np.random.randint(30, 225)\n",
        "        y = np.random.randint(30, 225)\n",
        "        w = 15\n",
        "        h = np.random.randint(80, 100)\n",
        "        theta = np.random.randint(-90, 90)\n",
        "        rect = ([x, y], [w, h], theta)\n",
        "        box = np.int0(cv2.boxPoints(rect))\n",
        "\n",
        "        gt = np.zeros_like(img)\n",
        "        gt = cv2.fillPoly(gt, [box], 1)\n",
        "        ins[:, gt != 0] = 0\n",
        "        ins = np.concatenate([ins, gt[np.newaxis]])\n",
        "        img = cv2.fillPoly(img, [box], 255)\n",
        "        img = cv2.drawContours(img, [box], 0, 0, 2)\n",
        "\n",
        "    if np.sum(np.sum(ins, axis=(1, 2)) < 400) == 0:\n",
        "        break"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Aud0B9doYcoq"
      },
      "source": [
        "# New Section"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y7AjIQKxWNLY"
      },
      "source": [
        "fig, axes = plt.subplots(1, 3, figsize=(15, 15))\n",
        "plt.gray()\n",
        "\n",
        "axes[0].imshow(img)\n",
        "axes[1].imshow(np.sum(ins, axis=0))\n",
        "axes[2].imshow(coloring(gen_mask(ins)))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nDlsBggkWfVj"
      },
      "source": [
        "from pathlib import Path\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.autograd import Variable\n"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q0p6YYNNcPBU"
      },
      "source": [
        "\"\"\"\n",
        "This implementation is based on following code:\n",
        "https://github.com/milesial/Pytorch-UNet\n",
        "\"\"\"\n",
        "\n",
        "import torch\n",
        "import e2cnn.nn as nn\n",
        "from e2cnn import gspaces\n",
        "\n",
        "class double_conveq(torch.nn.Module):\n",
        "    '''(conv => BN => ReLU) * 2'''\n",
        "    def __init__(self, in_ch, out_ch):\n",
        "        super(double_conveq, self).__init__()\n",
        "        self.conv = torch.nn.Sequential(\n",
        "            nn.PointwiseMaxPool(nn.FieldType(gspaces.Rot2dOnR2(N=4), in_ch*[gspaces.Rot2dOnR2(N=4).regular_repr]), kernel_size = 2),\n",
        "            nn.R2Conv(nn.FieldType(gspaces.Rot2dOnR2(N=4), in_ch*[gspaces.Rot2dOnR2(N=4).regular_repr]), nn.FieldType(gspaces.Rot2dOnR2(N=4), out_ch*[gspaces.Rot2dOnR2(N=4).regular_repr]), kernel_size=3, padding=1),\n",
        "            nn.InnerBatchNorm(nn.FieldType(gspaces.Rot2dOnR2(N=4), out_ch*[gspaces.Rot2dOnR2(N=4).regular_repr])),\n",
        "            nn.ReLU(nn.FieldType(gspaces.Rot2dOnR2(N=4), out_ch*[gspaces.Rot2dOnR2(N=4).regular_repr]), inplace=True),\n",
        "            nn.R2Conv(nn.FieldType(gspaces.Rot2dOnR2(N=4), out_ch*[gspaces.Rot2dOnR2(N=4).regular_repr]), nn.FieldType(gspaces.Rot2dOnR2(N=4), out_ch*[gspaces.Rot2dOnR2(N=4).regular_repr]), kernel_size=3, padding=1),\n",
        "            nn.InnerBatchNorm(nn.FieldType(gspaces.Rot2dOnR2(N=4), out_ch*[gspaces.Rot2dOnR2(N=4).regular_repr])),\n",
        "            nn.ReLU(nn.FieldType(gspaces.Rot2dOnR2(N=4), out_ch*[gspaces.Rot2dOnR2(N=4).regular_repr]), inplace=True)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        return x \n",
        "\n",
        "class double_conveq_up(torch.nn.Module):\n",
        "    '''(conv => BN => ReLU) * 2'''\n",
        "    def __init__(self, in_ch, out_ch):\n",
        "        super(double_conveq_up, self).__init__()\n",
        "        self.conv = torch.nn.Sequential(\n",
        "            nn.R2Conv(nn.FieldType(gspaces.Rot2dOnR2(N=4), in_ch*[gspaces.Rot2dOnR2(N=4).regular_repr]), nn.FieldType(gspaces.Rot2dOnR2(N=4), out_ch*[gspaces.Rot2dOnR2(N=4).regular_repr]), kernel_size=3, padding=1),\n",
        "            nn.InnerBatchNorm(nn.FieldType(gspaces.Rot2dOnR2(N=4), out_ch*[gspaces.Rot2dOnR2(N=4).regular_repr])),\n",
        "            nn.ReLU(nn.FieldType(gspaces.Rot2dOnR2(N=4), out_ch*[gspaces.Rot2dOnR2(N=4).regular_repr]), inplace=True),\n",
        "            nn.R2Conv(nn.FieldType(gspaces.Rot2dOnR2(N=4), out_ch*[gspaces.Rot2dOnR2(N=4).regular_repr]), nn.FieldType(gspaces.Rot2dOnR2(N=4), out_ch*[gspaces.Rot2dOnR2(N=4).regular_repr]), kernel_size=3, padding=1),\n",
        "            nn.InnerBatchNorm(nn.FieldType(gspaces.Rot2dOnR2(N=4), out_ch*[gspaces.Rot2dOnR2(N=4).regular_repr])),\n",
        "            nn.ReLU(nn.FieldType(gspaces.Rot2dOnR2(N=4), out_ch*[gspaces.Rot2dOnR2(N=4).regular_repr]), inplace=True)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        return x  \n",
        "\n",
        "class double_conveq_in(torch.nn.Module):\n",
        "    '''(conv => BN => ReLU) * 2'''\n",
        "    def __init__(self, in_ch, out_ch):\n",
        "        super(double_conveq_in, self).__init__()\n",
        "        self.conv = torch.nn.Sequential(\n",
        "            nn.R2Conv(nn.FieldType(gspaces.Rot2dOnR2(N=4), in_ch*[gspaces.Rot2dOnR2(N=4).trivial_repr]), nn.FieldType(gspaces.Rot2dOnR2(N=4), out_ch*[gspaces.Rot2dOnR2(N=4).regular_repr]), kernel_size=3, padding=1),\n",
        "            nn.InnerBatchNorm(nn.FieldType(gspaces.Rot2dOnR2(N=4), out_ch*[gspaces.Rot2dOnR2(N=4).regular_repr])),\n",
        "            nn.ReLU(nn.FieldType(gspaces.Rot2dOnR2(N=4), out_ch*[gspaces.Rot2dOnR2(N=4).regular_repr]), inplace=True),\n",
        "            nn.R2Conv(nn.FieldType(gspaces.Rot2dOnR2(N=4), out_ch*[gspaces.Rot2dOnR2(N=4).regular_repr]), nn.FieldType(gspaces.Rot2dOnR2(N=4), out_ch*[gspaces.Rot2dOnR2(N=4).regular_repr]), kernel_size=3, padding=1),\n",
        "            nn.InnerBatchNorm(nn.FieldType(gspaces.Rot2dOnR2(N=4), out_ch*[gspaces.Rot2dOnR2(N=4).regular_repr])),\n",
        "            nn.ReLU(nn.FieldType(gspaces.Rot2dOnR2(N=4), out_ch*[gspaces.Rot2dOnR2(N=4).regular_repr]), inplace=True)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        return x        \n",
        "\n",
        "\n",
        "class inconv(torch.nn.Module):\n",
        "    def __init__(self, in_ch, out_ch):\n",
        "        super(inconv, self).__init__()\n",
        "        self.conv = double_conveq_in(in_ch, out_ch)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = nn.GeometricTensor(x, nn.FieldType(gspaces.Rot2dOnR2(N=4), [gspaces.Rot2dOnR2(N=4).trivial_repr]))\n",
        "        x = self.conv(x)\n",
        "        return x\n",
        "\n",
        "class group_pool(torch.nn.Module):\n",
        "    def __init__(self, in_ch):\n",
        "        super(group_pool, self).__init__()\n",
        "        self.pool_group = nn.GroupPooling(nn.FieldType(gspaces.Rot2dOnR2(N=4), in_ch*[gspaces.Rot2dOnR2(N=4).regular_repr]))\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool_group(x)\n",
        "        return x        \n",
        "\n",
        "\n",
        "class down(torch.nn.Module):\n",
        "    def __init__(self, in_ch, out_ch):\n",
        "        super(down, self).__init__()\n",
        "        self.mpconv = torch.nn.Sequential(\n",
        "            double_conveq(in_ch, out_ch)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.mpconv(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class up(torch.nn.Module):\n",
        "    def __init__(self, in_ch, out_ch, bilinear=False):\n",
        "        super(up, self).__init__()\n",
        "\n",
        "        #  would be a nice idea if the upsampling could be learned too,\n",
        "        #  but my machine do not have enough memory to handle all those weights\n",
        "        if bilinear:\n",
        "            factor = int(in_ch/2)\n",
        "            self.up = nn.R2Upsampling(nn.FieldType(gspaces.Rot2dOnR2(N=4), factor*[gspaces.Rot2dOnR2(N=4).regular_repr]), scale_factor=2, mode='bilinear')\n",
        "        else:\n",
        "            factor = int(in_ch/2)\n",
        "            self.up = nn.R2ConvTransposed(nn.FieldType(gspaces.Rot2dOnR2(N=4), factor*[gspaces.Rot2dOnR2(N=4).regular_repr]), nn.FieldType(gspaces.Rot2dOnR2(N=4), factor*[gspaces.Rot2dOnR2(N=4).regular_repr]), kernel_size=2, stride=2, sigma=0.2)\n",
        "\n",
        "        self.conv = double_conveq_up(in_ch, out_ch)\n",
        "\n",
        "    def forward(self, x1, x2):\n",
        "        x1 = self.up(x1)\n",
        "        x=nn.tensor_directsum([x1, x2])\n",
        "        x = self.conv(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class outconv(torch.nn.Module):\n",
        "    def __init__(self, in_ch, out_ch):\n",
        "        super(outconv, self).__init__()\n",
        "        # self.conv = nn.Conv2d(in_ch, out_ch, 1)\n",
        "        factor = int(in_ch/2)\n",
        "        self.conv = torch.nn.Sequential(\n",
        "            #torch.nn.Conv2d(in_ch, in_ch//2, 1),\n",
        "            nn.R2Conv(nn.FieldType(gspaces.Rot2dOnR2(N=4), in_ch*[gspaces.Rot2dOnR2(N=4).regular_repr]), nn.FieldType(gspaces.Rot2dOnR2(N=4), factor*[gspaces.Rot2dOnR2(N=4).regular_repr]), kernel_size=3, padding=1),\n",
        "            nn.InnerBatchNorm(nn.FieldType(gspaces.Rot2dOnR2(N=4), factor*[gspaces.Rot2dOnR2(N=4).regular_repr])),\n",
        "            nn.ReLU(nn.FieldType(gspaces.Rot2dOnR2(N=4), factor*[gspaces.Rot2dOnR2(N=4).regular_repr]), inplace=True),\n",
        "            nn.R2Conv(nn.FieldType(gspaces.Rot2dOnR2(N=4), factor*[gspaces.Rot2dOnR2(N=4).regular_repr]), nn.FieldType(gspaces.Rot2dOnR2(N=4), out_ch*[gspaces.Rot2dOnR2(N=4).regular_repr]), kernel_size=3, padding=1),\n",
        "            #torch.nn.Conv2d(in_ch//2, out_ch, 1),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class UNet(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(UNet, self).__init__()\n",
        "        self.inc = inconv(1, 64) #self.inc = inconv(1, 64)\n",
        "        self.down1 = down(64, 128) #self.down1 = down(64, 128)\n",
        "        self.down2 = down(128, 256) #self.down2 = down(128, 256)\n",
        "        self.down3 = down(256, 512) #self.down3 = down(256, 512)\n",
        "        self.down4 = down(512, 512) #self.down4 = down(512, 512)\n",
        "        self.up1 = up(1024, 256)\n",
        "        self.up2 = up(512, 128)\n",
        "        self.up3 = up(256, 64)\n",
        "        self.up4 = up(128, 64)\n",
        "        self.sem_out = outconv(64, 2)\n",
        "        self.ins_out = outconv(64, 16)\n",
        "        self.gpool_sem = group_pool(2)\n",
        "        self.gpool_ins = group_pool(16)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x1 = self.inc(x)\n",
        "        x2 = self.down1(x1)\n",
        "        x3 = self.down2(x2)\n",
        "        x4 = self.down3(x3)\n",
        "        x5 = self.down4(x4)\n",
        "        x = self.up1(x5, x4)\n",
        "        x = self.up2(x, x3)\n",
        "        x = self.up3(x, x2)\n",
        "        x = self.up4(x, x1)\n",
        "        sem = self.sem_out(x)\n",
        "        ins = self.ins_out(x)\n",
        "        sem = self.gpool_sem(sem)\n",
        "        ins = self.gpool_ins(ins)\n",
        "        sem = sem.tensor\n",
        "        ins = ins.tensor\n",
        "        return sem, ins\n"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9sn_4jA-YNHf"
      },
      "source": [
        "n_sticks = 8"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UeZ05phFYQlM"
      },
      "source": [
        "# Model\n",
        "model = UNet().to(device)"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gUmxxfzzY5_V",
        "outputId": "559efc7c-4197-484c-82ac-c74dcbc7d219"
      },
      "source": [
        "# Dataset for train\n",
        "batchsize=1\n",
        "\n",
        "train_dataset = SSSDataset(train=True, n_sticks=n_sticks)\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=batchsize,\n",
        "                              shuffle=False, num_workers=0, pin_memory=True)\n",
        "\n",
        "print(len(train_dataset))"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "512\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "su0zi8yzZOG5"
      },
      "source": [
        "# Dataset for inference\n",
        "# Change to standard dataset if normal images wanted, rotated_90 if 1 image with 1 90-degree rotated copy\n",
        "test_dataset = SSSDataset(train=True, n_sticks=n_sticks, data_size=16)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=1,\n",
        "                             shuffle=False, num_workers=0,\n",
        "                             pin_memory=True)"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iJMnfIeJY8Q5"
      },
      "source": [
        "# Loss Function\n",
        "criterion_disc = DiscriminativeLoss(delta_var=0.5,\n",
        "                                    delta_dist=1.5,\n",
        "                                    norm=2,\n",
        "                                    usegpu=True)\n",
        "criterion_ce = torch.nn.CrossEntropyLoss()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SFyJ8KGhZDON"
      },
      "source": [
        "\n",
        "# Optimizer\n",
        "parameters = model.parameters()\n",
        "optimizer = optim.SGD(parameters, lr=0.01, momentum=0.9, weight_decay=0.001)\n",
        "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer=optimizer,\n",
        "                                                 mode='min',\n",
        "                                                 factor=0.1,\n",
        "                                                 patience=10,\n",
        "                                                 verbose=True)"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zOu1xuUgZF4x"
      },
      "source": [
        "# Train\n",
        "from scipy import ndimage as ndi\n",
        "\n",
        "model.train()\n",
        "best_loss = np.inf\n",
        "for epoch in range(100):#originally 300\n",
        "    print(f'epoch : {epoch}')\n",
        "    disc_losses = []\n",
        "    ce_losses = []\n",
        "    i=0\n",
        "    dice_complete = 0\n",
        "\n",
        "    sem_pred_eval = []\n",
        "    ins_pred_eval = []\n",
        "    p_sem_pred_eval = []\n",
        "\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    model = model.to(device)\n",
        "    for batched in train_dataloader:\n",
        "        \n",
        "        #print(f'batched : {batched}')\n",
        "        images, sem_labels, ins_labels = batched\n",
        "        images = Variable(images)\n",
        "        sem_labels = Variable(sem_labels)\n",
        "        ins_labels = Variable(ins_labels)\n",
        "\n",
        "        images = images.to(device)\n",
        "        sem_labels = sem_labels.to(device)\n",
        "        ins_labels = ins_labels.to(device)\n",
        "        model.zero_grad()\n",
        "\n",
        "        sem_predict, ins_predict = model(images)\n",
        "        if i == 0:\n",
        "          sem_pred_eval.append(F.softmax(sem_predict, dim=1).cpu().data.numpy())\n",
        "          ins_pred_eval.append(ins_predict.cpu().data.numpy())\n",
        "          sem_pred_eval = np.concatenate(sem_pred_eval)[:, 1, :, :]\n",
        "          ins_pred_eval = np.concatenate(ins_pred_eval)\n",
        "\n",
        "        loss = 0\n",
        "\n",
        "        # Discriminative Loss\n",
        "        disc_loss = criterion_disc(ins_predict,\n",
        "                                   ins_labels,\n",
        "                                   [n_sticks] * len(images))\n",
        "        loss += disc_loss\n",
        "\n",
        "        disc_losses.append(disc_loss.cpu().data.numpy())\n",
        "\n",
        "        # Cross Entropy Loss\n",
        "        _, sem_labels_ce = sem_labels.max(1)\n",
        "        ce_loss = criterion_ce(sem_predict.permute(0, 2, 3, 1)\\\n",
        "                                   .contiguous().view(-1, 2),\n",
        "                               sem_labels_ce.view(-1))\n",
        "        loss += ce_loss\n",
        "        ce_losses.append(ce_loss.cpu().data.numpy())\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Evaluation by DICE score\n",
        "\n",
        "        if i == 0:\n",
        "          p_sem_pred_eval.append(ndi.morphology.binary_fill_holes(sem_pred_eval[0] > 0.5))\n",
        "          pred_eval = gen_color_img(p_sem_pred_eval[0], ins_pred_eval[0], n_sticks)\n",
        "          groundtruth_eval = coloring(gen_mask(ins_labels[0].cpu()))\n",
        "\n",
        "          pred_eval = pred_eval[:,:,1] #I have checked that no two colors have the same values in this channel. They are: 232, 81, 159, 1, 217, 79, 247, 165\n",
        "          groundtruth_eval = groundtruth_eval[:,:,1]\n",
        "\n",
        "          dice_total = 0\n",
        "          colors_pred = [232, 81, 159, 1, 217, 79, 247, 165]\n",
        "          colors_gt = [232, 81, 159, 1, 217, 79, 247, 165]\n",
        "\n",
        "          for y in range(1,8):\n",
        "            a = np.array(groundtruth_eval==colors_gt[0]).astype(int)\n",
        "            Area_GT = np.count_nonzero(a)\n",
        "            Overlap = 0\n",
        "            for x in colors_pred:\n",
        "               b = np.array(pred_eval==x).astype(int)\n",
        "               Overlap_temp = np.count_nonzero(np.multiply(a,b))*2\n",
        "               if (Overlap_temp > Overlap):\n",
        "                  Overlap = Overlap_temp\n",
        "                  x_temp = x\n",
        "                  Area_Pred = np.count_nonzero(b)\n",
        "            if (Overlap > 0):     #If no match, keep all the predicted sticks. One of them might match another ground truth.\n",
        "              colors_pred.remove(x_temp)\n",
        "            del colors_gt[0]\n",
        "            dice_temp = Overlap / ((Area_GT)+(Area_Pred))\n",
        "            dice_total = dice_total+dice_temp \n",
        "\n",
        "          #background\n",
        "          a = np.array(groundtruth_eval==0).astype(int)\n",
        "          Area_GT = np.count_nonzero(a)\n",
        "          b = np.array(pred_eval==0).astype(int)\n",
        "          Overlap = np.count_nonzero(np.multiply(a,b))*2\n",
        "          Area_Pred = np.count_nonzero(b)\n",
        "          dice_background = Overlap / ((Area_GT)+(Area_Pred))\n",
        "          dice_total = dice_total+dice_background \n",
        "    \n",
        "          print('Total Dice similarity score is {}'.format(dice_total/9))\n",
        "          dice_complete = dice_complete + dice_total/9\n",
        "\n",
        "        i=i+1\n",
        "\n",
        "    disc_loss = np.mean(disc_losses)\n",
        "    ce_loss = np.mean(ce_losses)\n",
        "    print(f'DiscriminativeLoss: {disc_loss:.4f}')\n",
        "    print(f'CrossEntropyLoss: {ce_loss:.4f}')\n",
        "    scheduler.step(disc_loss)\n",
        "    if disc_loss < best_loss:\n",
        "        best_loss = disc_loss\n",
        "\n",
        "    # Inference\n",
        "    device = torch.device('cpu')\n",
        "    model = model.to(device)\n",
        "\n",
        "    ins_labels_test_all = []\n",
        "    images = []\n",
        "    sem_pred = []\n",
        "    ins_pred = []\n",
        "\n",
        "    for images_ in test_dataloader:\n",
        "      images_test, sem_labels_test, ins_labels_test = images_\n",
        "      ins_labels_test_all.append(coloring(gen_mask(ins_labels_test[0])))\n",
        "\n",
        "      images.append(images_test.numpy())\n",
        "    \n",
        "      with torch.no_grad():\n",
        "        sem_pred_, ins_pred_ = model(images_test)\n",
        "        sem_pred.append(F.softmax(sem_pred_, dim=1).cpu().data.numpy())\n",
        "        ins_pred.append(ins_pred_.cpu().data.numpy())\n",
        "\n",
        "    images = np.concatenate(images)[:, 0].astype(np.uint8)\n",
        "    sem_pred = np.concatenate(sem_pred)[:, 1, :, :]\n",
        "    ins_pred = np.concatenate(ins_pred)\n",
        "\n",
        "    # Post Processing\n",
        "    p_sem_pred = []\n",
        "    for sp in sem_pred:\n",
        "      p_sem_pred.append(ndi.morphology.binary_fill_holes(sp > 0.5))\n",
        "\n",
        "    # Evaluation by DICE score\n",
        "\n",
        "    dice_complete = 0\n",
        "    Area_GT=0\n",
        "    Area_Pred=0\n",
        "    Overlap_temp=0\n",
        "    dice_background=0\n",
        "    dice_temp=0\n",
        "    x=0\n",
        "    x_temp=0\n",
        "    for i in range(0, 16):\n",
        "      pred = gen_color_img(p_sem_pred[i], ins_pred[i], n_sticks)\n",
        "      groundtruth = ins_labels_test_all[i]\n",
        "\n",
        "      pred = pred[:,:,1] #I have checked that no two colors have the same values in this channel. They are: 232, 81, 159, 1, 217, 79, 247, 165\n",
        "      groundtruth = groundtruth[:,:,1]\n",
        "\n",
        "      dice_total = 0\n",
        "      colors_pred = [232, 81, 159, 1, 217, 79, 247, 165]\n",
        "      colors_gt = [232, 81, 159, 1, 217, 79, 247, 165]\n",
        "\n",
        "      for y in range(1,8):\n",
        "        a = np.array(groundtruth==colors_gt[0]).astype(int)\n",
        "        Area_GT = np.count_nonzero(a)\n",
        "        Overlap = 0\n",
        "        for x in colors_pred:\n",
        "          b = np.array(pred==x).astype(int)\n",
        "          Overlap_temp = np.count_nonzero(np.multiply(a,b))*2\n",
        "          if (Overlap_temp > Overlap):\n",
        "            Overlap = Overlap_temp\n",
        "            x_temp = x\n",
        "            Area_Pred = np.count_nonzero(b)\n",
        "        if (Overlap > 0):     #If no match, keep all the predicted sticks. One of them might match another ground truth.\n",
        "            colors_pred.remove(x_temp)\n",
        "        del colors_gt[0]\n",
        "        dice_temp = Overlap / ((Area_GT)+(Area_Pred))\n",
        "        dice_total = dice_total+dice_temp \n",
        "\n",
        "      #background\n",
        "      a = np.array(groundtruth==0).astype(int)\n",
        "      Area_GT = np.count_nonzero(a)\n",
        "      b = np.array(pred==0).astype(int)\n",
        "      Overlap = np.count_nonzero(np.multiply(a,b))*2\n",
        "      Area_Pred = np.count_nonzero(b)\n",
        "      dice_background = Overlap / ((Area_GT)+(Area_Pred))\n",
        "      dice_total = dice_total+dice_background \n",
        "    \n",
        "      dice_complete = dice_complete + dice_total/9\n",
        "\n",
        "    print('Test set: Complete Dice similarity score is {}'.format(dice_complete/16))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UBut5h9GpeUM"
      },
      "source": [
        "from scipy import ndimage as ndi\n",
        "\n",
        "np.random.seed(0)"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nHfzDnXMpnlS"
      },
      "source": [
        "model.eval()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EH2d39MW_3BO"
      },
      "source": [
        "# New Section"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Er2d3bgpywZ"
      },
      "source": [
        "# Inference\n",
        "device = torch.device('cpu')\n",
        "model = model.to(device)\n",
        "\n",
        "ins_labels_test_all = []\n",
        "images = []\n",
        "sem_pred = []\n",
        "ins_pred = []\n",
        "\n",
        "for images_ in test_dataloader:\n",
        "    images_test, sem_labels_test, ins_labels_test = images_\n",
        "    ins_labels_test_all.append(coloring(gen_mask(ins_labels_test[0])))\n",
        "\n",
        "    images.append(images_test.numpy())\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        sem_pred_, ins_pred_ = model(images_test)\n",
        "        sem_pred.append(F.softmax(sem_pred_, dim=1).cpu().data.numpy())\n",
        "        ins_pred.append(ins_pred_.cpu().data.numpy())\n",
        "\n",
        "images = np.concatenate(images)[:, 0].astype(np.uint8)\n",
        "sem_pred = np.concatenate(sem_pred)[:, 1, :, :]\n",
        "ins_pred = np.concatenate(ins_pred)\n",
        "\n"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UZnR8-Lap_GH"
      },
      "source": [
        "# Post Processing\n",
        "p_sem_pred = []\n",
        "for sp in sem_pred:\n",
        "    p_sem_pred.append(ndi.morphology.binary_fill_holes(sp > 0.5))"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "62ypwrpoqBKu"
      },
      "source": [
        "fig, axes = plt.subplots(16, 3, figsize=(15, 15))\n",
        "plt.gray()\n",
        "\n",
        "for i, ax_ in enumerate(axes):\n",
        "    color_img = gen_color_img(p_sem_pred[i], ins_pred[i], n_sticks)\n",
        "    ax_[0].imshow(images[i])\n",
        "    ax_[1].imshow(~p_sem_pred[i])\n",
        "    ax_[2].imshow(color_img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wuA9_AifNee9"
      },
      "source": [
        "#This one for a single image\n",
        "\n",
        "fig, axes = plt.subplots(figsize=(15, 15))\n",
        "plt.gray()\n",
        "\n",
        "color_img = gen_color_img(p_sem_pred[0], ins_pred[0], n_sticks)\n",
        "axes.imshow(color_img)\n",
        "\n",
        "fig2, axes2 = plt.subplots(figsize=(15, 15))\n",
        "plt.gray()\n",
        "\n",
        "color_img2 = gen_color_img(p_sem_pred[1], ins_pred[1], n_sticks)\n",
        "axes2.imshow(color_img2)\n",
        "\n",
        "fig3, axes3 = plt.subplots(figsize=(15, 15))\n",
        "plt.gray()\n",
        "\n",
        "color_img3 = gen_color_img(p_sem_pred[2], ins_pred[2], n_sticks)\n",
        "axes3.imshow(color_img3)\n",
        "\n",
        "fig4, axes4 = plt.subplots(figsize=(15, 15))\n",
        "plt.gray()\n",
        "\n",
        "color_img4 = gen_color_img(p_sem_pred[3], ins_pred[3], n_sticks)\n",
        "axes4.imshow(color_img3)\n",
        "\n",
        "fig5, axes5 = plt.subplots(figsize=(15, 15))\n",
        "plt.gray()\n",
        "\n",
        "color_img5 = gen_color_img(p_sem_pred[4], ins_pred[4], n_sticks)\n",
        "axes5.imshow(color_img5)\n",
        "\n",
        "fig6, axes6 = plt.subplots(figsize=(15, 15))\n",
        "plt.gray()\n",
        "\n",
        "color_img6 = gen_color_img(p_sem_pred[5], ins_pred[5], n_sticks)\n",
        "axes6.imshow(color_img6)\n",
        "\n",
        "fig7, axes7 = plt.subplots(figsize=(15, 15))\n",
        "plt.gray()\n",
        "\n",
        "color_img7 = gen_color_img(p_sem_pred[6], ins_pred[6], n_sticks)\n",
        "axes7.imshow(color_img7)\n",
        "\n",
        "fig8, axes8 = plt.subplots(figsize=(15, 15))\n",
        "plt.gray()\n",
        "\n",
        "color_img8 = gen_color_img(p_sem_pred[7], ins_pred[7], n_sticks)\n",
        "axes8.imshow(color_img8)\n",
        "\n",
        "fig9, axes9 = plt.subplots(figsize=(15, 15))\n",
        "plt.gray()\n",
        "\n",
        "color_img9 = gen_color_img(p_sem_pred[8], ins_pred[8], n_sticks)\n",
        "axes9.imshow(color_img9)\n",
        "\n",
        "fig10, axes10 = plt.subplots(figsize=(15, 15))\n",
        "plt.gray()\n",
        "\n",
        "color_img10 = gen_color_img(p_sem_pred[9], ins_pred[9], n_sticks)\n",
        "axes10.imshow(color_img10)\n",
        "\n",
        "fig11, axes11 = plt.subplots(figsize=(15, 15))\n",
        "plt.gray()\n",
        "\n",
        "color_img11 = gen_color_img(p_sem_pred[10], ins_pred[10], n_sticks)\n",
        "axes11.imshow(color_img11)\n",
        "\n",
        "fig12, axes12 = plt.subplots(figsize=(15, 15))\n",
        "plt.gray()\n",
        "\n",
        "color_img12 = gen_color_img(p_sem_pred[11], ins_pred[11], n_sticks)\n",
        "axes12.imshow(color_img12)\n",
        "\n",
        "fig13, axes13 = plt.subplots(figsize=(15, 15))\n",
        "plt.gray()\n",
        "\n",
        "color_img13 = gen_color_img(p_sem_pred[12], ins_pred[12], n_sticks)\n",
        "axes13.imshow(color_img13)\n",
        "\n",
        "fig14, axes14 = plt.subplots(figsize=(15, 15))\n",
        "plt.gray()\n",
        "\n",
        "color_img14 = gen_color_img(p_sem_pred[13], ins_pred[13], n_sticks)\n",
        "axes14.imshow(color_img14)\n",
        "\n",
        "fig15, axes15 = plt.subplots(figsize=(15, 15))\n",
        "plt.gray()\n",
        "\n",
        "color_img15 = gen_color_img(p_sem_pred[14], ins_pred[14], n_sticks)\n",
        "axes15.imshow(color_img15)\n",
        "\n",
        "fig16, axes16 = plt.subplots(figsize=(15, 15))\n",
        "plt.gray()\n",
        "\n",
        "color_img16 = gen_color_img(p_sem_pred[15], ins_pred[15], n_sticks)\n",
        "axes16.imshow(color_img16)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2w8OTrlPpfOI"
      },
      "source": [
        "# Evaluation by DICE score\n",
        "\n",
        "dice_complete = 0\n",
        "for i in range(0, 16):\n",
        "  pred = gen_color_img(p_sem_pred[i], ins_pred[i], n_sticks)\n",
        "  groundtruth = ins_labels_test_all[i]\n",
        "\n",
        "  pred = pred[:,:,1] #I have checked that no two colors have the same values in this channel. They are: 232, 81, 159, 1, 217, 79, 247, 165\n",
        "  groundtruth = groundtruth[:,:,1]\n",
        "\n",
        "  dice_total = 0\n",
        "  colors_pred = [232, 81, 159, 1, 217, 79, 247, 165]\n",
        "  colors_gt = [232, 81, 159, 1, 217, 79, 247, 165]\n",
        "\n",
        "  # This to fix the ground truth label, and compare with all the labels of the prediction.\n",
        "  # Remove the label with highest overlap.\n",
        "  # Compute Dice Score for this instance.\n",
        "  # Continue until no more labels left.\n",
        "  # Calculate background Dice.\n",
        "  # Finally compute total Dice Score.\n",
        "  for y in range(1,8):\n",
        "    a = np.array(groundtruth==colors_gt[0]).astype(int)\n",
        "    Area_GT = np.count_nonzero(a)\n",
        "    Overlap = 0\n",
        "    for x in colors_pred:\n",
        "      b = np.array(pred==x).astype(int)\n",
        "      Overlap_temp = np.count_nonzero(np.multiply(a,b))*2\n",
        "      if (Overlap_temp > Overlap):\n",
        "        Overlap = Overlap_temp\n",
        "        x_temp = x\n",
        "        Area_Pred = np.count_nonzero(b)\n",
        "    if (Overlap > 0):     #If no match, keep all the predicted sticks. One of them might match another ground truth.\n",
        "      colors_pred.remove(x_temp)\n",
        "    del colors_gt[0]\n",
        "    dice_temp = Overlap / ((Area_GT)+(Area_Pred))\n",
        "    dice_total = dice_total+dice_temp \n",
        "\n",
        "  #background\n",
        "  a = np.array(groundtruth==0).astype(int)\n",
        "  Area_GT = np.count_nonzero(a)\n",
        "  b = np.array(pred==0).astype(int)\n",
        "  Overlap = np.count_nonzero(np.multiply(a,b))*2\n",
        "  Area_Pred = np.count_nonzero(b)\n",
        "  dice_background = Overlap / ((Area_GT)+(Area_Pred))\n",
        "  dice_total = dice_total+dice_background \n",
        "    \n",
        "  print('Total Dice similarity score is {}'.format(dice_total/9))\n",
        "  dice_complete = dice_complete + dice_total/9\n",
        "\n",
        "print('Complete Dice similarity score is {}'.format(dice_complete/16))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}